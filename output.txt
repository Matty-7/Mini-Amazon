=== PROJECT FILE STRUCTURE ===
  |  |-config.cpython-313.pyc
  |-alembic.ini
  |  |-__init__.py
  |  |  |-__init__.cpython-313.pyc
  |  |  |-db.cpython-313.pyc
  |  |-db.py
  |  |  |-__init__.py
  |  |  |  |-__init__.cpython-313.pyc
  |  |  |  |-base.cpython-313.pyc
  |  |  |  |-product.cpython-313.pyc
  |  |  |  |-shipment.cpython-313.pyc
  |  |  |  |-warehouse.cpython-313.pyc
  |  |  |-base.py
  |  |  |-product.py
  |  |  |-shipment.py
  |  |  |-warehouse.py
  |  |  |-__init__.py
  |  |  |  |-__init__.cpython-313.pyc
  |  |  |  |-world_amazon_1_pb2.cpython-313.pyc
  |  |  |-amazon_ups_pb2.py
  |  |  |-world_amazon_1_pb2.py
  |  |  |-__init__.py
  |  |  |-amazon_ups.proto
  |  |  |-world_amazon-1.proto
  |  |  |  |-inventory_service.cpython-313.pyc
  |  |  |  |-world_client.cpython-313.pyc
  |  |  |-inventory_service.py
  |  |  |-ups_client.py
  |  |  |-world_client.py
  |  |  |  |-reliable_channel.cpython-313.pyc
  |  |  |-reliable_channel.py
  |-app.py
  |-config.py
  |-docker-compose.yml
  |-Dockerfile
  |-Makefile
  |  |  |-env.cpython-313.pyc
  |  |-env.py
  |  |-README
  |  |-script.py.mako
  |  |  |  |-init_tables.cpython-313.pyc
  |  |  |-init_tables.py
  |-output.txt
  |-print_all.sh
  |-project_spec-1.pdf
  |  |-amazon_ups.proto
  |  |-world_amazon-1.proto
  |-pytest.ini
  |-README.md
  |-requirements.txt
  |  |-compile_protos.sh
  |-setup.py
  |-smoke_test.sh
  |  |  |-test_world_client_extended.cpython-313-pytest-8.3.5.pyc
  |  |  |-test_world_client.cpython-313-pytest-8.3.5.pyc
  |  |-test_world_client_extended.py
  |  |-test_world_client.py
  |  |  |-__init__.py
  |  |  |  |-__init__.cpython-313.pyc
  |  |  |  |-test_models.cpython-313-pytest-8.3.5.pyc
  |  |  |-test_models.py
  |  |  |-docker-compose.yml
  |  |  |-Dockerfile
  |  |  |-server
  |  |  |-wait-for-it.sh
  |  |-README.md
  |-world.pcap


./
./migrations/

--- File: ./migrations/env.py ---
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

from amazon_app.models.base import Base
import sys, os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import DATABASE_URL

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Override sqlalchemy.url from alembic.ini
config.set_main_option("sqlalchemy.url", "postgresql+psycopg2://amazon:amazon@localhost:5432/amazon")

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    try:
        connectable = engine_from_config(
            config.get_section(config.config_ini_section, {}),
            prefix="sqlalchemy.",
            poolclass=pool.NullPool,
        )

        with connectable.connect() as connection:
            context.configure(
                connection=connection, target_metadata=target_metadata
            )

            with context.begin_transaction():
                context.run_migrations()
    except Exception as e:
        print(f"Error connecting to database: {e}")
        print("Falling back to offline mode...")
        run_migrations_offline()


# Call online migration instead of offline
run_migrations_online()
./migrations/versions/
./migrations/versions/__pycache__/

--- File: ./migrations/versions/init_tables.py ---
"""init tables

Revision ID: 9a6e9d9d4f2c
Revises: 
Create Date: 2023-11-01 00:00:00.000000

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '9a6e9d9d4f2c'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # Create warehouses table
    op.create_table(
        'warehouses',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('x', sa.Integer(), nullable=False),
        sa.Column('y', sa.Integer(), nullable=False),
        sa.PrimaryKeyConstraint('id')
    )

    # Create products table
    op.create_table(
        'products',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('description', sa.String(), nullable=False),
        sa.Column('stock', sa.Integer(), nullable=False, server_default='0'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create shipments table
    op.create_table(
        'shipments',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('whnum', sa.Integer(), nullable=False),
        sa.Column('items', sa.JSON(), nullable=False),
        sa.Column('dest_x', sa.Integer(), nullable=False),
        sa.Column('dest_y', sa.Integer(), nullable=False),
        sa.Column('status', sa.String(), nullable=False, server_default='packing'),
        sa.ForeignKeyConstraint(['whnum'], ['warehouses.id'], ),
        sa.PrimaryKeyConstraint('id')
    )


def downgrade() -> None:
    op.drop_table('shipments')
    op.drop_table('products')
    op.drop_table('warehouses') 
./migrations/__pycache__/
./protos/

--- File: ./protos/amazon_ups.proto ---
syntax = "proto2";
package edu.duke.ece568.project.Protos;

message AmazonToUPS {
  repeated int64 acks = 123;
  repeated RequestPickup request_pickup = 1;
  repeated Redirect redirect = 2;
  repeated Cancel cancel = 3;
  repeated LoadReady load_ready = 4;
}

message UPSToAmazon {
  repeated int64 acks = 123;
  repeated PickupResp pickup_resp = 1;
  repeated RedirectResp redirect_resp = 2;
  repeated CancelResp cancel_resp = 3;
  repeated TruckArrived truck_arrived = 4;
  repeated DeliveryStarted delivery_started = 5;
  repeated DeliveryComplete delivery_complete = 6;
}

message Coordinate {
  required int32 x = 1;
  required int32 y = 2;
}

message ItemInfo {
  required string item_name = 1;
  required int32 quantity = 2;
}

//Amazon to UPS
message RequestPickup {
  required int64 seqnum = 123;
  required int64 ups_user_id = 1;
  repeated ItemInfo items = 2;
  required int64 order_id = 3;
  required int32 warehouse_id = 4;
  required Coordinate user_destination = 5;
}

message Redirect {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required Coordinate new_destination = 2;
}

message Cancel {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message LoadReady {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message ReturnAck {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

// UPS to Amazon

message PickupResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required int64 order_id = 2;
  required int32 truck_id = 3;
}


message RedirectResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required bool success = 2;
  required string reason = 3;
}

message CancelResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required bool success = 2;
  required string reason = 3;
}

message TruckArrived {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required int32 truck_id = 2;
  required int32 warehouse_id = 3;
}

message DeliveryStarted {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message DeliveryComplete {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

--- File: ./protos/world_amazon-1.proto ---
syntax = "proto2";
message AProduct{
  required int64 id = 1;
  required string description = 2;
  required int32 count = 3;
}

message AInitWarehouse{
  required int32 id = 1;
  required int32 x = 2;
  required int32 y = 3;
}

message AConnect{
  optional int64 worldid = 1;
  repeated AInitWarehouse initwh = 2;
  required bool isAmazon = 3;
}

message AConnected{
  required int64 worldid= 1;
  required string result = 2;
}

message APack{
  required int32 whnum = 1;
  repeated AProduct things = 2;
  required int64 shipid = 3;
  required int64 seqnum = 4;
}
message APacked {
  required int64 shipid = 1;
  required int64 seqnum = 2;
}

message ALoaded{
  required int64 shipid = 1;
  required int64 seqnum = 2;
}

message APutOnTruck{
  required int32 whnum = 1;
  required int32 truckid = 2;
  required int64 shipid = 3;
  required int64 seqnum = 4;
}

message APurchaseMore{
  required int32 whnum = 1;
  repeated AProduct things = 2;
  required int64 seqnum = 3;
}

message AErr{
  required string err = 1;
  required int64 originseqnum = 2;
  required int64 seqnum = 3;
}

message AQuery{
  required int64 packageid = 1;
  required int64 seqnum = 2;
}

message APackage{
  required int64 packageid =1;
  required string status = 2;
  required int64 seqnum = 3;
}

message ACommands {
  repeated APurchaseMore buy = 1;
  repeated APack topack = 2; 
  repeated APutOnTruck load = 3;
  repeated AQuery queries = 4;
  optional uint32 simspeed = 5; 
  optional bool disconnect = 6;
  repeated int64 acks =7;
}

message AResponses {
  repeated APurchaseMore arrived = 1;
  repeated APacked ready = 2; 
  repeated ALoaded loaded = 3; 
  optional bool finished = 4;
  repeated AErr error = 5;
  repeated int64 acks = 6;
  repeated APackage packagestatus = 7;
}


--- File: ./config.py ---
import os

WORLD_HOST = os.getenv("WORLD_HOST", "ece650-vm.colab.duke.edu")
WORLD_PORT = os.getenv("WORLD_PORT", 23456)

INITIAL_WAREHOUSES_DATA = [
    {'id': 1, 'x': 10, 'y': 20},
    {'id': 2, 'x': 50, 'y': 60},
]

SIM_SPEED = int(os.getenv("SIM_SPEED", 1))

DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql+psycopg2://amazon:amazon@localhost:5432/amazon",
)

./test/
./test/__pycache__/

--- File: ./test/test_world_client.py ---
# Import pytest only when running through pytest, not when run directly
try:
    import pytest
    pytestmark = pytest.mark.integration
except ImportError:
    pass  # Skip when run directly

# Adjust path for direct script execution
import sys
import os
# Add the project root directory to Python path when run directly
if __name__ == "__main__":
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from amazon_app.services.world_client import WorldClient
import amazon_app.pb_generated.world_amazon_1_pb2 as wam
import socket
import argparse
import logging
import queue
# Set up logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Test World Client')
    parser.add_argument('--host', default="ece650-vm.colab.duke.edu", 
                        help='Server hostname (default: ece650-vm.colab.duke.edu)')
    parser.add_argument('--port', type=int, default=23456, 
                        help='Server port (default: 23456)')
    args = parser.parse_args()
    
    hostname = args.host
    port = args.port
    
    try:
        # First check if the server is reachable
        print(f"Verifying connection to {hostname}:{port}...")
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        
        try:
            result = sock.connect_ex((hostname, port))
            if result != 0:
                print(f"Error: Could not connect to {hostname}:{port}")
                print(f"Error code: {result}")
                sys.exit(1)
            sock.close()
            print(f"Successfully connected to {hostname}:{port}")
        except socket.error as e:
            print(f"Socket error: {e}")
            sys.exit(1)
        
        # Now proceed with the client
        client = WorldClient(hostname, port, queue.Queue())
        
        # connect to world
        print("Connecting to world...")
        client.connect([
            wam.AInitWarehouse(id=1, x=3, y=4)
        ])
        print("Connected successfully!")

        # simulate purchase
        print("Buying product...")
        product = wam.AProduct(id=101, description="book", count=5)
        client.buy(1, [product])

        # simulate pack
        print("Packing product...")
        client.pack(1, [product], 10001)

        # simulate load
        print("Loading product...")
        client.load(1, truckid=1, shipid=10001)

        # simulate query
        print("Querying package...")
        client.query(packageid=10001)
        
        print("Test completed successfully")

    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Make sure to cleanly shutdown the client
        if 'client' in locals():
            print("Shutting down client...")
            client.shutdown()

--- File: ./test/test_world_client_extended.py ---
"""
WorldClient – pure‑unit tests (no live World Simulator needed).

Strategy
--------
‣ Replace the TCP socket with an in‑memory DummySocket.
‣ Pre‑enqueue framed protobuf responses into DummySocket.recvq to simulate
  the server.
‣ Verify that WorldClient sends correctly framed AConnect/ACommands messages
  and that ACK bookkeeping clears the retransmit queue.
"""
from __future__ import annotations

import queue
import socket
import struct
from typing import Tuple, List

import pytest
from google.protobuf.internal.encoder import _VarintBytes

import amazon_app.pb_generated.world_amazon_1_pb2 as wam
from amazon_app.services.world_client import WorldClient


# --------------------------------------------------------------------------- #
# Utilities                                                                   #
# --------------------------------------------------------------------------- #
def frame(pb_msg) -> bytes:
    """Return the bytes <varint32 len><protobuf payload> exactly as the
    World Simulator expects (same algorithm as ReliableChannel._frame)."""
    body: bytes = pb_msg.SerializeToString()
    return _VarintBytes(len(body)) + body


def drain(q: "queue.Queue[bytes]") -> List[bytes]:
    """Drain *all* frames still sitting in DummySocket.sent for easy assertions."""
    out: List[bytes] = []
    while not q.empty():
        out.append(q.get_nowait())
    return out


# --------------------------------------------------------------------------- #
# Fake socket                                                                 #
# --------------------------------------------------------------------------- #
class DummySocket:
    """Minimal drop‑in replacement for a blocking TCP socket."""

    def __init__(self):
        self.sent: "queue.Queue[bytes]" = queue.Queue()
        self.recvq: "queue.Queue[bytes]" = queue.Queue()
        self._closed = False

    # ----- tx/rx API -------------------------------------------------------- #
    def sendall(self, data: bytes):
        self.sent.put(data)
        
    def recv(self, n: int) -> bytes:
        """
        Block until at least one byte is available, exactly like a real
        TCP socket in blocking mode (the default that ReliableChannel uses).

        Returning *zero* bytes would tell ReliableChannel that the peer
        closed the connection, so we must not do that here.
        """
        chunk = self.recvq.get()          # ← blocks until data present
        if len(chunk) > n:                # respect caller's `n`
            rest = chunk[n:]
            self.recvq.put_nowait(rest)   # push back extra bytes
            chunk = chunk[:n]
        return chunk


    # ----- misc standard methods ------------------------------------------- #
    def setsockopt(self, *_, **__):  # TCP_NODELAY — ignored
        pass

    def shutdown(self, _how):  # SHUT_RDWR
        self._closed = True

    def close(self):
        self._closed = True

    def getpeername(self):
        return ("dummy", 0)

    # python‑style helpers --------------------------------------------------- #
    @property
    def closed(self) -> bool:
        return self._closed


# --------------------------------------------------------------------------- #
# PyTest fixtures                                                             #
# --------------------------------------------------------------------------- #
@pytest.fixture()
def dummy_socket(monkeypatch) -> DummySocket:
    sock = DummySocket()
    monkeypatch.setattr("socket.create_connection", lambda addr, timeout=None: sock)
    # speed up retransmit thread so the test suite finishes instantly
    monkeypatch.setattr(
        "amazon_app.utils.reliable_channel.RetryInterval", 0.02, raising=False
    )
    return sock


@pytest.fixture()
def wc(dummy_socket) -> Tuple[WorldClient, DummySocket]:
    """Returns (world_client, dummy_socket)."""
    response_queue = queue.Queue()
    return WorldClient("dummy", 12345, response_queue), dummy_socket


# --------------------------------------------------------------------------- #
# Tests                                                                       #
# --------------------------------------------------------------------------- #
def _enqueue_handshake(sock: DummySocket, worldid: int = 1):
    """Push an AConnected frame into the recv queue so that the very next
    wc.connect() call succeeds immediately."""
    connected = wam.AConnected(worldid=worldid, result="connected!")
    sock.recvq.put(frame(connected))


def test_full_buy_pack_load_query_cycle(wc):
    client, sock = wc
    _enqueue_handshake(sock)

    # 1 CONNECT ------------------------------------------------------------- #
    client.connect([wam.AInitWarehouse(id=1, x=3, y=4)])

    # 2 BUY — immediately ACK it so retransmit queue is cleared ------------- #
    client.buy(1, [wam.AProduct(id=42, description="book", count=3)])
    sock.recvq.put(frame(wam.AResponses(acks=[1])))

    # 3 PACK / LOAD --------------------------------------------------------- #
    client.pack(1, [wam.AProduct(id=42, description="book", count=3)], shipid=888)
    client.load(1, truckid=5, shipid=888)

    # 4 QUERY --------------------------------------------------------------- #
    client.query(packageid=888)

    # flush any protocol frames that went out
    frames = drain(sock.sent)

    # — at least four outbound frames:
    #   • AConnect
    #   • ACommands(BUY)
    #   • ACommands(PACK + LOAD)  ← WorldClient batches pack+load separately
    #   • ACommands(QUERY)
    assert len(frames) >= 4

    # quick sanity‑check: first outbound frame *must* be an AConnect
    first_payload = frames[0][1:]  # skip size varint
    assert wam.AConnect.FromString(first_payload).isAmazon is True


def test_shutdown_closes_socket(wc):
    client, sock = wc
    _enqueue_handshake(sock)
    client.connect([])
    client.shutdown()
    assert sock.closed is True
./amazon_app/

--- File: ./amazon_app/db.py ---
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from config import DATABASE_URL

engine = create_engine(DATABASE_URL, pool_pre_ping=True, echo=False)
SessionLocal = sessionmaker(bind=engine, expire_on_commit=False) 

--- File: ./amazon_app/__init__.py ---
from flask import Flask

def create_app():
    # Initialize your application
    app = Flask(__name__)
    
    @app.route('/')
    def index():
        return "Amazon App is running!"
    
    return app  # Return your Flask application instance
./amazon_app/utils/

--- File: ./amazon_app/utils/reliable_channel.py ---
"""High‑level *ReliableChannel* wrapper for the Mini‑Amazon/UPS World Simulator.

Key properties
--------------
* **Varint‑framed protobuf** – each outbound frame is prefixed with a Varint32
  length, exactly as required by the world server.
* **Exactly‑once semantics** – every *business* request carries a `seqnum`; the
  same frame is stored under those sequence numbers until an ACK arrives in a
  later `AResponses.acks` list. Frames are resent with exponential back‑off
  until ACKed or the connection is shut down.
* **Thread‑safe** – `.send()` may be called concurrently; a dedicated reader
  thread feeds a thread‑safe queue for callers to `.recv()`.

This refactor removes the earlier brittle `WhichOneof("")` call and aligns the
pending‑ACK bookkeeping with the World Simulator's contract: the server ACKs
**child request** `seqnum`s – not some hidden transport ID – so we map every
child's `seqnum` to the raw frame for retransmission.
"""

from __future__ import annotations

import logging
import socket
import threading
import time
from queue import Empty, Queue
from typing import Dict, Generic, List, Optional, TypeVar

from google.protobuf.internal.decoder import _DecodeVarint32
from google.protobuf.message import Message

logger = logging.getLogger(__name__)

T = TypeVar("T", bound=Message)


class ChannelClosed(RuntimeError):
    """Raised when the underlying TCP connection is irrecoverably closed."""


class ReliableChannel(Generic[T]):
    """Bi‑directional *exactly‑once* channel with automatic retransmission."""

    RETRY_INTERVAL_S: float = 0.5  # initial back‑off base

    def __init__(self, host: str, port: int) -> None:
        self._sock = socket.create_connection((host, port))
        self._sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)

        self._tx_lock = threading.Lock()
        self._seq: int = 0  # transport‑level fallback seq allocator
        self._pending: Dict[int, bytes] = {}  # seqnum → raw frame

        self._rx_q: "Queue[bytes]" = Queue()
        self._shutdown = threading.Event()

        threading.Thread(target=self._recv_loop, daemon=True).start()
        threading.Thread(target=self._retransmit_loop, daemon=True).start()
        
    @property
    def remote(self):
        return self._sock.getpeername()
        
    @property
    def closed(self) -> bool:
        return self._shutdown.is_set()

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def send(self, pb_msg: Message) -> List[int]:
        """Serialize *pb_msg*, transmit it, and return **all** seqnums carried."""
        with self._tx_lock:
            carried: List[int] = self._extract_seqnums(pb_msg)

            # If nothing carried (e.g. AConnect), allocate a transport id
            if not carried:
                # 纯粹的控制/心跳帧（如空 ACommands）不做 pending-ACK 追踪
                raw_frame = self._frame(pb_msg.SerializeToString())
                logger.info("Sending %s (no-seq)", pb_msg.DESCRIPTOR.name)
                self._sock.sendall(raw_frame)
                return []

            raw_frame = self._frame(pb_msg.SerializeToString())
            logger.info("Sending %s (seqs=%s)", pb_msg.DESCRIPTOR.name, carried)
            self._sock.sendall(raw_frame)

            for s in carried:
                self._pending[s] = raw_frame
            return carried

    def recv(self, timeout: Optional[float] = None) -> Optional[bytes]:
        try:
            return self._rx_q.get(timeout=timeout)
        except Empty:
            return None

    def close(self) -> None:
        self._shutdown.set()
        try:
            self._sock.shutdown(socket.SHUT_RDWR)
        except OSError:
            pass
        finally:
            self._sock.close()

    def pending_acks(self) -> List[int]:
        return list(self._pending.keys())

    def mark_acked(self, ack: int) -> None:
        self._pending.pop(ack, None)

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _extract_seqnums(self, msg: Message) -> List[int]:
        """Return **all** non‑zero `seqnum` fields contained in *msg*."""
        seqs: List[int] = []

        def _maybe_add(m):
            if hasattr(m, "seqnum"):
                val = getattr(m, "seqnum")
                if val:
                    seqs.append(val)

        if msg.DESCRIPTOR.name == "ACommands":
            for fld in msg.DESCRIPTOR.fields:
                if fld.label == fld.LABEL_REPEATED and fld.message_type:
                    for sub in getattr(msg, fld.name):
                        _maybe_add(sub)
        else:
            _maybe_add(msg)
        return seqs

    @staticmethod
    def _frame(body: bytes) -> bytes:
        size = len(body)
        header = bytearray()
        while size > 127:
            header.append((size & 0x7F) | 0x80)
            size >>= 7
        header.append(size & 0x7F)
        return bytes(header) + body

    # ----------------------------- background loops -------------------
    def _recv_loop(self) -> None:
        buf = bytearray()
        try:
            while not self._shutdown.is_set():
                chunk = self._sock.recv(4096)
                if not chunk:
                    lvl = logger.info if self._shutdown.is_set() else logger.error
                    lvl("TCP connection closed%s", " locally" if self._shutdown.is_set() else " by peer")
                    raise ChannelClosed()
                buf.extend(chunk)
                while True:
                    try:
                        msg_len, idx = _DecodeVarint32(buf, 0)
                    except IndexError:
                        break  # incomplete varint
                    if len(buf) - idx < msg_len:
                        break  # incomplete payload
                    payload = bytes(buf[idx : idx + msg_len])
                    del buf[: idx + msg_len]
                    self._rx_q.put(payload)
        except ChannelClosed:
            pass
        except Exception as exc:  # noqa: BLE001
            logger.exception("recv loop died: %s", exc)
        finally:
            self._shutdown.set()

    def _retransmit_loop(self) -> None:
        interval = self.RETRY_INTERVAL_S
        while not self._shutdown.is_set():
            time.sleep(interval)
            for seq, frame in list(self._pending.items()):
                try:
                    self._sock.sendall(frame)
                    logger.debug("Retransmitted seq=%d", seq)
                except OSError as exc:
                    logger.error("Retransmit failed: %s", exc)
                    self._shutdown.set()
                    break
            interval = min(interval * 2, 4 * self.RETRY_INTERVAL_S)
./amazon_app/utils/__pycache__/
./amazon_app/models/

--- File: ./amazon_app/models/warehouse.py ---
from sqlalchemy import Integer, Column
from .base import Base

class Warehouse(Base):
    __tablename__ = "warehouses"
    id = Column(Integer, primary_key=True)
    x  = Column(Integer, nullable=False)
    y  = Column(Integer, nullable=False) 

--- File: ./amazon_app/models/__init__.py ---
# Models package 

from .base import Base
from .warehouse import Warehouse
from .product import Product
from .shipment import Shipment 
./amazon_app/models/__pycache__/

--- File: ./amazon_app/models/product.py ---
from sqlalchemy import Integer, Column, String
from .base import Base

class Product(Base):
    __tablename__ = "products"
    id          = Column(Integer, primary_key=True)
    description = Column(String, nullable=False)
    stock       = Column(Integer, default=0) 

--- File: ./amazon_app/models/base.py ---
from sqlalchemy.orm import DeclarativeBase

class Base(DeclarativeBase):
    pass 

--- File: ./amazon_app/models/shipment.py ---
from sqlalchemy import Integer, Column, String, ForeignKey, JSON
from sqlalchemy.orm import relationship, Mapped, mapped_column
from .base import Base

class Shipment(Base):
    __tablename__ = "shipments"
    id: Mapped[int]          = mapped_column(Integer, primary_key=True)
    whnum: Mapped[int]       = mapped_column(Integer, ForeignKey("warehouses.id"))
    items: Mapped[dict]      = mapped_column(JSON)        # {product_id: qty}
    dest_x: Mapped[int]      = mapped_column(Integer)
    dest_y: Mapped[int]      = mapped_column(Integer)
    status: Mapped[str]      = mapped_column(String, default="packing")

    warehouse = relationship("Warehouse") 
./amazon_app/__pycache__/
./amazon_app/protocols/

--- File: ./amazon_app/protocols/__init__.py ---
# Protocols package 

--- File: ./amazon_app/protocols/amazon_ups.proto ---
syntax = "proto2";
package edu.duke.ece568.project.Protos;

message AmazonToUPS {
  repeated int64 acks = 123;
  repeated RequestPickup request_pickup = 1;
  repeated Redirect redirect = 2;
  repeated Cancel cancel = 3;
  repeated LoadReady load_ready = 4;
}

message UPSToAmazon {
  repeated int64 acks = 123;
  repeated PickupResp pickup_resp = 1;
  repeated RedirectResp redirect_resp = 2;
  repeated CancelResp cancel_resp = 3;
  repeated TruckArrived truck_arrived = 4;
  repeated DeliveryStarted delivery_started = 5;
  repeated DeliveryComplete delivery_complete = 6;
}

message Coordinate {
  required int32 x = 1;
  required int32 y = 2;
}

message ItemInfo {
  required string item_name = 1;
  required int32 quantity = 2;
}

//Amazon to UPS
message RequestPickup {
  required int64 seqnum = 123;
  required int64 ups_user_id = 1;
  repeated ItemInfo items = 2;
  required int64 order_id = 3;
  required int32 warehouse_id = 4;
  required Coordinate user_destination = 5;
}

message Redirect {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required Coordinate new_destination = 2;
}

message Cancel {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message LoadReady {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message ReturnAck {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

// UPS to Amazon

message PickupResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required int64 order_id = 2;
  required int32 truck_id = 3;
}


message RedirectResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required bool success = 2;
  required string reason = 3;
}

message CancelResp {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required bool success = 2;
  required string reason = 3;
}

message TruckArrived {
  required int64 seqnum = 123;
  required int64 package_id = 1;
  required int32 truck_id = 2;
  required int32 warehouse_id = 3;
}

message DeliveryStarted {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

message DeliveryComplete {
  required int64 seqnum = 123;
  required int64 package_id = 1;
}

--- File: ./amazon_app/protocols/world_amazon_1_pb2.py ---
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: world_amazon-1.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'world_amazon-1.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x14world_amazon-1.proto\":\n\x08\x41Product\x12\n\n\x02id\x18\x01 \x02(\x03\x12\x13\n\x0b\x64\x65scription\x18\x02 \x02(\t\x12\r\n\x05\x63ount\x18\x03 \x02(\x05\"2\n\x0e\x41InitWarehouse\x12\n\n\x02id\x18\x01 \x02(\x05\x12\t\n\x01x\x18\x02 \x02(\x05\x12\t\n\x01y\x18\x03 \x02(\x05\"N\n\x08\x41\x43onnect\x12\x0f\n\x07worldid\x18\x01 \x01(\x03\x12\x1f\n\x06initwh\x18\x02 \x03(\x0b\x32\x0f.AInitWarehouse\x12\x10\n\x08isAmazon\x18\x03 \x02(\x08\"-\n\nAConnected\x12\x0f\n\x07worldid\x18\x01 \x02(\x03\x12\x0e\n\x06result\x18\x02 \x02(\t\"Q\n\x05\x41Pack\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x19\n\x06things\x18\x02 \x03(\x0b\x32\t.AProduct\x12\x0e\n\x06shipid\x18\x03 \x02(\x03\x12\x0e\n\x06seqnum\x18\x04 \x02(\x03\")\n\x07\x41Packed\x12\x0e\n\x06shipid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\")\n\x07\x41Loaded\x12\x0e\n\x06shipid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\"M\n\x0b\x41PutOnTruck\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x0f\n\x07truckid\x18\x02 \x02(\x05\x12\x0e\n\x06shipid\x18\x03 \x02(\x03\x12\x0e\n\x06seqnum\x18\x04 \x02(\x03\"I\n\rAPurchaseMore\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x19\n\x06things\x18\x02 \x03(\x0b\x32\t.AProduct\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"9\n\x04\x41\x45rr\x12\x0b\n\x03\x65rr\x18\x01 \x02(\t\x12\x14\n\x0coriginseqnum\x18\x02 \x02(\x03\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"+\n\x06\x41Query\x12\x11\n\tpackageid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\"=\n\x08\x41Package\x12\x11\n\tpackageid\x18\x01 \x02(\x03\x12\x0e\n\x06status\x18\x02 \x02(\t\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"\xaa\x01\n\tACommands\x12\x1b\n\x03\x62uy\x18\x01 \x03(\x0b\x32\x0e.APurchaseMore\x12\x16\n\x06topack\x18\x02 \x03(\x0b\x32\x06.APack\x12\x1a\n\x04load\x18\x03 \x03(\x0b\x32\x0c.APutOnTruck\x12\x18\n\x07queries\x18\x04 \x03(\x0b\x32\x07.AQuery\x12\x10\n\x08simspeed\x18\x05 \x01(\r\x12\x12\n\ndisconnect\x18\x06 \x01(\x08\x12\x0c\n\x04\x61\x63ks\x18\x07 \x03(\x03\"\xb8\x01\n\nAResponses\x12\x1f\n\x07\x61rrived\x18\x01 \x03(\x0b\x32\x0e.APurchaseMore\x12\x17\n\x05ready\x18\x02 \x03(\x0b\x32\x08.APacked\x12\x18\n\x06loaded\x18\x03 \x03(\x0b\x32\x08.ALoaded\x12\x10\n\x08\x66inished\x18\x04 \x01(\x08\x12\x14\n\x05\x65rror\x18\x05 \x03(\x0b\x32\x05.AErr\x12\x0c\n\x04\x61\x63ks\x18\x06 \x03(\x03\x12 \n\rpackagestatus\x18\x07 \x03(\x0b\x32\t.APackage')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'world_amazon_1_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_APRODUCT']._serialized_start=24
  _globals['_APRODUCT']._serialized_end=82
  _globals['_AINITWAREHOUSE']._serialized_start=84
  _globals['_AINITWAREHOUSE']._serialized_end=134
  _globals['_ACONNECT']._serialized_start=136
  _globals['_ACONNECT']._serialized_end=214
  _globals['_ACONNECTED']._serialized_start=216
  _globals['_ACONNECTED']._serialized_end=261
  _globals['_APACK']._serialized_start=263
  _globals['_APACK']._serialized_end=344
  _globals['_APACKED']._serialized_start=346
  _globals['_APACKED']._serialized_end=387
  _globals['_ALOADED']._serialized_start=389
  _globals['_ALOADED']._serialized_end=430
  _globals['_APUTONTRUCK']._serialized_start=432
  _globals['_APUTONTRUCK']._serialized_end=509
  _globals['_APURCHASEMORE']._serialized_start=511
  _globals['_APURCHASEMORE']._serialized_end=584
  _globals['_AERR']._serialized_start=586
  _globals['_AERR']._serialized_end=643
  _globals['_AQUERY']._serialized_start=645
  _globals['_AQUERY']._serialized_end=688
  _globals['_APACKAGE']._serialized_start=690
  _globals['_APACKAGE']._serialized_end=751
  _globals['_ACOMMANDS']._serialized_start=754
  _globals['_ACOMMANDS']._serialized_end=924
  _globals['_ARESPONSES']._serialized_start=927
  _globals['_ARESPONSES']._serialized_end=1111
# @@protoc_insertion_point(module_scope)

--- File: ./amazon_app/protocols/world_amazon-1.proto ---
syntax = "proto2";
message AProduct{
  required int64 id = 1;
  required string description = 2;
  required int32 count = 3;
}

message AInitWarehouse{
  required int32 id = 1;
  required int32 x = 2;
  required int32 y = 3;
}

message AConnect{
  optional int64 worldid = 1;
  repeated AInitWarehouse initwh = 2;
  required bool isAmazon = 3;
}

message AConnected{
  required int64 worldid= 1;
  required string result = 2;
}

message APack{
  required int32 whnum = 1;
  repeated AProduct things = 2;
  required int64 shipid = 3;
  required int64 seqnum = 4;
}
message APacked {
  required int64 shipid = 1;
  required int64 seqnum = 2;
}

message ALoaded{
  required int64 shipid = 1;
  required int64 seqnum = 2;
}

message APutOnTruck{
  required int32 whnum = 1;
  required int32 truckid = 2;
  required int64 shipid = 3;
  required int64 seqnum = 4;
}

message APurchaseMore{
  required int32 whnum = 1;
  repeated AProduct things = 2;
  required int64 seqnum = 3;
}

message AErr{
  required string err = 1;
  required int64 originseqnum = 2;
  required int64 seqnum = 3;
}

message AQuery{
  required int64 packageid = 1;
  required int64 seqnum = 2;
}

message APackage{
  required int64 packageid =1;
  required string status = 2;
  required int64 seqnum = 3;
}

message ACommands {
  repeated APurchaseMore buy = 1;
  repeated APack topack = 2; 
  repeated APutOnTruck load = 3;
  repeated AQuery queries = 4;
  optional uint32 simspeed = 5; 
  optional bool disconnect = 6;
  repeated int64 acks =7;
}

message AResponses {
  repeated APurchaseMore arrived = 1;
  repeated APacked ready = 2; 
  repeated ALoaded loaded = 3; 
  optional bool finished = 4;
  repeated AErr error = 5;
  repeated int64 acks = 6;
  repeated APackage packagestatus = 7;
}

./amazon_app/pb_generated/

--- File: ./amazon_app/pb_generated/__init__.py ---
./amazon_app/pb_generated/__pycache__/

--- File: ./amazon_app/pb_generated/amazon_ups_pb2.py ---
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: amazon_ups.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'amazon_ups.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x61mazon_ups.proto\x12\x1e\x65\x64u.duke.ece568.project.Protos\"\x95\x02\n\x0b\x41mazonToUPS\x12\x0c\n\x04\x61\x63ks\x18{ \x03(\x03\x12\x45\n\x0erequest_pickup\x18\x01 \x03(\x0b\x32-.edu.duke.ece568.project.Protos.RequestPickup\x12:\n\x08redirect\x18\x02 \x03(\x0b\x32(.edu.duke.ece568.project.Protos.Redirect\x12\x36\n\x06\x63\x61ncel\x18\x03 \x03(\x0b\x32&.edu.duke.ece568.project.Protos.Cancel\x12=\n\nload_ready\x18\x04 \x03(\x0b\x32).edu.duke.ece568.project.Protos.LoadReady\"\xbf\x03\n\x0bUPSToAmazon\x12\x0c\n\x04\x61\x63ks\x18{ \x03(\x03\x12?\n\x0bpickup_resp\x18\x01 \x03(\x0b\x32*.edu.duke.ece568.project.Protos.PickupResp\x12\x43\n\rredirect_resp\x18\x02 \x03(\x0b\x32,.edu.duke.ece568.project.Protos.RedirectResp\x12?\n\x0b\x63\x61ncel_resp\x18\x03 \x03(\x0b\x32*.edu.duke.ece568.project.Protos.CancelResp\x12\x43\n\rtruck_arrived\x18\x04 \x03(\x0b\x32,.edu.duke.ece568.project.Protos.TruckArrived\x12I\n\x10\x64\x65livery_started\x18\x05 \x03(\x0b\x32/.edu.duke.ece568.project.Protos.DeliveryStarted\x12K\n\x11\x64\x65livery_complete\x18\x06 \x03(\x0b\x32\x30.edu.duke.ece568.project.Protos.DeliveryComplete\"\"\n\nCoordinate\x12\t\n\x01x\x18\x01 \x02(\x05\x12\t\n\x01y\x18\x02 \x02(\x05\"/\n\x08ItemInfo\x12\x11\n\titem_name\x18\x01 \x02(\t\x12\x10\n\x08quantity\x18\x02 \x02(\x05\"\xdb\x01\n\rRequestPickup\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x13\n\x0bups_user_id\x18\x01 \x02(\x03\x12\x37\n\x05items\x18\x02 \x03(\x0b\x32(.edu.duke.ece568.project.Protos.ItemInfo\x12\x10\n\x08order_id\x18\x03 \x02(\x03\x12\x14\n\x0cwarehouse_id\x18\x04 \x02(\x05\x12\x44\n\x10user_destination\x18\x05 \x02(\x0b\x32*.edu.duke.ece568.project.Protos.Coordinate\"s\n\x08Redirect\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\x12\x43\n\x0fnew_destination\x18\x02 \x02(\x0b\x32*.edu.duke.ece568.project.Protos.Coordinate\",\n\x06\x43\x61ncel\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\"/\n\tLoadReady\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\"/\n\tReturnAck\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\"T\n\nPickupResp\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\x12\x10\n\x08order_id\x18\x02 \x02(\x03\x12\x10\n\x08truck_id\x18\x03 \x02(\x05\"S\n\x0cRedirectResp\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\x12\x0f\n\x07success\x18\x02 \x02(\x08\x12\x0e\n\x06reason\x18\x03 \x02(\t\"Q\n\nCancelResp\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\x12\x0f\n\x07success\x18\x02 \x02(\x08\x12\x0e\n\x06reason\x18\x03 \x02(\t\"Z\n\x0cTruckArrived\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\x12\x10\n\x08truck_id\x18\x02 \x02(\x05\x12\x14\n\x0cwarehouse_id\x18\x03 \x02(\x05\"5\n\x0f\x44\x65liveryStarted\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03\"6\n\x10\x44\x65liveryComplete\x12\x0e\n\x06seqnum\x18{ \x02(\x03\x12\x12\n\npackage_id\x18\x01 \x02(\x03')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'amazon_ups_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_AMAZONTOUPS']._serialized_start=53
  _globals['_AMAZONTOUPS']._serialized_end=330
  _globals['_UPSTOAMAZON']._serialized_start=333
  _globals['_UPSTOAMAZON']._serialized_end=780
  _globals['_COORDINATE']._serialized_start=782
  _globals['_COORDINATE']._serialized_end=816
  _globals['_ITEMINFO']._serialized_start=818
  _globals['_ITEMINFO']._serialized_end=865
  _globals['_REQUESTPICKUP']._serialized_start=868
  _globals['_REQUESTPICKUP']._serialized_end=1087
  _globals['_REDIRECT']._serialized_start=1089
  _globals['_REDIRECT']._serialized_end=1204
  _globals['_CANCEL']._serialized_start=1206
  _globals['_CANCEL']._serialized_end=1250
  _globals['_LOADREADY']._serialized_start=1252
  _globals['_LOADREADY']._serialized_end=1299
  _globals['_RETURNACK']._serialized_start=1301
  _globals['_RETURNACK']._serialized_end=1348
  _globals['_PICKUPRESP']._serialized_start=1350
  _globals['_PICKUPRESP']._serialized_end=1434
  _globals['_REDIRECTRESP']._serialized_start=1436
  _globals['_REDIRECTRESP']._serialized_end=1519
  _globals['_CANCELRESP']._serialized_start=1521
  _globals['_CANCELRESP']._serialized_end=1602
  _globals['_TRUCKARRIVED']._serialized_start=1604
  _globals['_TRUCKARRIVED']._serialized_end=1694
  _globals['_DELIVERYSTARTED']._serialized_start=1696
  _globals['_DELIVERYSTARTED']._serialized_end=1749
  _globals['_DELIVERYCOMPLETE']._serialized_start=1751
  _globals['_DELIVERYCOMPLETE']._serialized_end=1805
# @@protoc_insertion_point(module_scope)

--- File: ./amazon_app/pb_generated/world_amazon_1_pb2.py ---
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: world_amazon-1.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'world_amazon-1.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x14world_amazon-1.proto\":\n\x08\x41Product\x12\n\n\x02id\x18\x01 \x02(\x03\x12\x13\n\x0b\x64\x65scription\x18\x02 \x02(\t\x12\r\n\x05\x63ount\x18\x03 \x02(\x05\"2\n\x0e\x41InitWarehouse\x12\n\n\x02id\x18\x01 \x02(\x05\x12\t\n\x01x\x18\x02 \x02(\x05\x12\t\n\x01y\x18\x03 \x02(\x05\"N\n\x08\x41\x43onnect\x12\x0f\n\x07worldid\x18\x01 \x01(\x03\x12\x1f\n\x06initwh\x18\x02 \x03(\x0b\x32\x0f.AInitWarehouse\x12\x10\n\x08isAmazon\x18\x03 \x02(\x08\"-\n\nAConnected\x12\x0f\n\x07worldid\x18\x01 \x02(\x03\x12\x0e\n\x06result\x18\x02 \x02(\t\"Q\n\x05\x41Pack\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x19\n\x06things\x18\x02 \x03(\x0b\x32\t.AProduct\x12\x0e\n\x06shipid\x18\x03 \x02(\x03\x12\x0e\n\x06seqnum\x18\x04 \x02(\x03\")\n\x07\x41Packed\x12\x0e\n\x06shipid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\")\n\x07\x41Loaded\x12\x0e\n\x06shipid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\"M\n\x0b\x41PutOnTruck\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x0f\n\x07truckid\x18\x02 \x02(\x05\x12\x0e\n\x06shipid\x18\x03 \x02(\x03\x12\x0e\n\x06seqnum\x18\x04 \x02(\x03\"I\n\rAPurchaseMore\x12\r\n\x05whnum\x18\x01 \x02(\x05\x12\x19\n\x06things\x18\x02 \x03(\x0b\x32\t.AProduct\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"9\n\x04\x41\x45rr\x12\x0b\n\x03\x65rr\x18\x01 \x02(\t\x12\x14\n\x0coriginseqnum\x18\x02 \x02(\x03\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"+\n\x06\x41Query\x12\x11\n\tpackageid\x18\x01 \x02(\x03\x12\x0e\n\x06seqnum\x18\x02 \x02(\x03\"=\n\x08\x41Package\x12\x11\n\tpackageid\x18\x01 \x02(\x03\x12\x0e\n\x06status\x18\x02 \x02(\t\x12\x0e\n\x06seqnum\x18\x03 \x02(\x03\"\xaa\x01\n\tACommands\x12\x1b\n\x03\x62uy\x18\x01 \x03(\x0b\x32\x0e.APurchaseMore\x12\x16\n\x06topack\x18\x02 \x03(\x0b\x32\x06.APack\x12\x1a\n\x04load\x18\x03 \x03(\x0b\x32\x0c.APutOnTruck\x12\x18\n\x07queries\x18\x04 \x03(\x0b\x32\x07.AQuery\x12\x10\n\x08simspeed\x18\x05 \x01(\r\x12\x12\n\ndisconnect\x18\x06 \x01(\x08\x12\x0c\n\x04\x61\x63ks\x18\x07 \x03(\x03\"\xb8\x01\n\nAResponses\x12\x1f\n\x07\x61rrived\x18\x01 \x03(\x0b\x32\x0e.APurchaseMore\x12\x17\n\x05ready\x18\x02 \x03(\x0b\x32\x08.APacked\x12\x18\n\x06loaded\x18\x03 \x03(\x0b\x32\x08.ALoaded\x12\x10\n\x08\x66inished\x18\x04 \x01(\x08\x12\x14\n\x05\x65rror\x18\x05 \x03(\x0b\x32\x05.AErr\x12\x0c\n\x04\x61\x63ks\x18\x06 \x03(\x03\x12 \n\rpackagestatus\x18\x07 \x03(\x0b\x32\t.APackage')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'world_amazon_1_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_APRODUCT']._serialized_start=24
  _globals['_APRODUCT']._serialized_end=82
  _globals['_AINITWAREHOUSE']._serialized_start=84
  _globals['_AINITWAREHOUSE']._serialized_end=134
  _globals['_ACONNECT']._serialized_start=136
  _globals['_ACONNECT']._serialized_end=214
  _globals['_ACONNECTED']._serialized_start=216
  _globals['_ACONNECTED']._serialized_end=261
  _globals['_APACK']._serialized_start=263
  _globals['_APACK']._serialized_end=344
  _globals['_APACKED']._serialized_start=346
  _globals['_APACKED']._serialized_end=387
  _globals['_ALOADED']._serialized_start=389
  _globals['_ALOADED']._serialized_end=430
  _globals['_APUTONTRUCK']._serialized_start=432
  _globals['_APUTONTRUCK']._serialized_end=509
  _globals['_APURCHASEMORE']._serialized_start=511
  _globals['_APURCHASEMORE']._serialized_end=584
  _globals['_AERR']._serialized_start=586
  _globals['_AERR']._serialized_end=643
  _globals['_AQUERY']._serialized_start=645
  _globals['_AQUERY']._serialized_end=688
  _globals['_APACKAGE']._serialized_start=690
  _globals['_APACKAGE']._serialized_end=751
  _globals['_ACOMMANDS']._serialized_start=754
  _globals['_ACOMMANDS']._serialized_end=924
  _globals['_ARESPONSES']._serialized_start=927
  _globals['_ARESPONSES']._serialized_end=1111
# @@protoc_insertion_point(module_scope)
./amazon_app/services/

--- File: ./amazon_app/services/inventory_service.py ---
from __future__ import annotations

from enum import Enum, auto
from typing import Dict, Optional
import logging
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError

from amazon_app.models.product import Product
from amazon_app.models.shipment import Shipment
from amazon_app.pb_generated.world_amazon_1_pb2 import ACommands as pb
from .world_client import ReliableChannel

logger = logging.getLogger(__name__)


class ShipmentStatus(str, Enum):
    PACKING = "packing"
    PACKED = "packed"
    LOADING = "loading"
    LOADED = "loaded"
    DELIVERING = "delivering"
    DELIVERED = "delivered"


class InventoryService:
    """High‑level façade combining DB operations and world/UPS side‑effects."""

    def __init__(self, db_session_factory, world_channel: ReliableChannel[pb.AResponses]):
        self._db_session_factory = db_session_factory
        self._world = world_channel

    # ------------------------------------------------------------------
    # Public API – called by Flask route handlers
    # ------------------------------------------------------------------

    def create_order(
        self,
        whnum: int,
        items: Dict[int, int],  # product_id -> cnt
        user_dest: tuple[int, int],
    ) -> int:
        """Insert DB rows, send APack to world, return *shipid*."""
        with self._db_session_factory() as db:  # type: Session
            # 1) Ensure inventory has enough stock; if not, raise 409
            for prod_id, cnt in items.items():
                prod: Product = db.get(Product, prod_id)
                if prod is None or prod.stock < cnt:
                    raise ValueError("Insufficient inventory for product %d" % prod_id)
            # 2) Allocate new shipid (auto‑inc seq in DB)
            ship = Shipment.create(db, whnum, items, user_dest)  # type: ignore[arg-type]
            db.commit()
        # 3) Send topack cmd
        apack = pb.APack(whnum=whnum, shipid=ship.id, seqnum=0)
        for pid, cnt in items.items():
            apack.things.add(id=pid, description="", count=cnt)
        self._world.send(apack)  # seqnum set inside
        logger.info("Order %d created & APack sent", ship.id)
        return ship.id

    def query_status(self, shipid: int) -> ShipmentStatus:
        with self._db_session_factory() as db:
            ship: Optional[Shipment] = db.get(Shipment, shipid)
            if ship is None:
                raise KeyError("Unknown shipment %d" % shipid)
            return ShipmentStatus(ship.status)

    # ------------------------------------------------------------------
    # World event processing – called by background consumer thread
    # ------------------------------------------------------------------

    def on_world_message(self, resp: pb.AResponses) -> None:
        """Handle *AResponses* and perform DB transitions (idempotent)."""
        with self._db_session_factory() as db:  # noqa: SIM117
            # 1) inventory arrived  ➜ increment stock
            for arrive in resp.arrived:
                for p in arrive.things:
                    self._inc_stock(db, p.id, p.count)
            # 2) ready / loaded state transitions
            for ready in resp.ready:
                self._update_status(db, ready.shipid, ShipmentStatus.PACKED)
            for loaded in resp.loaded:
                self._update_status(db, loaded.shipid, ShipmentStatus.LOADED)
            # 3) package status reply (queried)
            for pkg in resp.packagestatus:
                self._update_status(db, pkg.packageid, ShipmentStatus(pkg.status))
            db.commit()
            # ACK housekeeping
            for ack in resp.acks:
                self._world.mark_acked(ack)

    # --------------------------- helpers ------------------------------

    def _inc_stock(self, db: Session, pid: int, delta: int) -> None:
        prod: Product | None = db.get(Product, pid)
        if prod is None:
            prod = Product(id=pid, description="auto", stock=0)
            db.add(prod)
        prod.stock += delta

    def _update_status(self, db: Session, shipid: int, new_status: ShipmentStatus) -> None:
        ship: Shipment | None = db.get(Shipment, shipid)
        if ship is None:
            logger.warning("Received event for unknown shipment %d", shipid)
            return
        # idempotent: only advance if makes sense
        cur = ShipmentStatus(ship.status)
        order = [
            ShipmentStatus.PACKING,
            ShipmentStatus.PACKED,
            ShipmentStatus.LOADING,
            ShipmentStatus.LOADED,
            ShipmentStatus.DELIVERING,
            ShipmentStatus.DELIVERED,
        ]
        if order.index(new_status) > order.index(cur):
            ship.status = new_status.value
./amazon_app/services/__pycache__/

--- File: ./amazon_app/services/ups_client.py ---

--- File: ./amazon_app/services/world_client.py ---
from __future__ import annotations
import logging
import threading
import queue
import time
from typing import List, Optional, Dict, Any
import amazon_app.pb_generated.world_amazon_1_pb2 as wam
from amazon_app.utils.reliable_channel import ChannelClosed, ReliableChannel

logger = logging.getLogger(__name__)


class WorldClient:
    HEARTBEAT_SEC = 2  # ≤ World 的 idle-timeout，实测 2 s 足够

    def __init__(self, host: str, port: int, response_queue: queue.Queue, simspeed: int = 1, start_seq: int = 1):
        self._chan: ReliableChannel[wam.AResponses] = ReliableChannel(host, port)
        self._seq = start_seq - 1  # 允许从高值开始，避免seqnum冲突
        self._lock = threading.Lock()
        self._running = False
        self._response_queue = response_queue
        self._simspeed = simspeed
        self._hb_thread: threading.Thread | None = None
        self._acks_to_send: list[int] = []  # 收集需要回传给World的ACK
        self._pending_pack: list[tuple[int, list[wam.AProduct], int]] = []
        self._inventory_ready: set[int] = set()  # whnum that already received stock
        # 存储每个仓库最近收到的商品信息，用于PACK验证
        self._last_arrived: Dict[int, List[Dict[str, Any]]] = {}

    def connect(self, warehouses: List[wam.AInitWarehouse], *, timeout: int = 30) -> Optional[int]:
        logger.info("Connecting to world %s:%d …", *self._chan.remote)
        try:
            conn = wam.AConnect(isAmazon=True)
            conn.initwh.extend(warehouses)
            self._chan.send(conn) # Removed .SerializeToString() assuming ReliableChannel handles it

            raw = self._chan.recv(timeout)
            if raw is None:
                logger.error(f"World simulator did not reply within {timeout}s")
                raise RuntimeError(f"World simulator did not reply within {timeout}s")

            ack = wam.AConnected()
            ack.ParseFromString(raw)
            if ack.result != "connected!":
                logger.error(f"Handshake rejected: {ack.result}")
                raise RuntimeError(f"Handshake rejected: {ack.result}")
            logger.info("Handshake OK, worldid=%d", ack.worldid)

            # Send initial empty command with simspeed right after successful connection
            logger.info(f"Sending initial empty command with simspeed={self._simspeed}")
            initial_cmd = wam.ACommands(simspeed=self._simspeed)
            self._chan.send(initial_cmd)

            self._running = True
            threading.Thread(target=self._recv_loop, daemon=True).start()
            
            # 启动心跳线程
            self._hb_thread = threading.Thread(target=self._heartbeat_loop, daemon=True)
            self._hb_thread.start()
            logger.info("Heartbeat thread started")
            
            return ack.worldid
        except (RuntimeError, ConnectionRefusedError, Exception) as e:
             logger.exception(f"Failed to connect to world: {e}")
             self.shutdown()
             return None

    def buy(self, wh: int, prods: List[wam.AProduct]):
        self._enqueue_buy(wh, prods)

    def pack(self, wh: int, prods: List[wam.AProduct], shipid: int):
        self._enqueue_pack(wh, prods, shipid)

    def load(self, wh: int, truckid: int, shipid: int):
        self._enqueue_load(wh, truckid, shipid)

    def query(self, packageid: int):
        self._enqueue_query(packageid)

    def _next_seq(self) -> int:
        with self._lock:
            self._seq += 1
            return self._seq

    def _dispatch(self, cmd: wam.ACommands):
        if not self._running:
            logger.warning("Attempted to dispatch command but client is not running.")
            return
        try:
            # Always include simspeed in every command
            cmd.simspeed = self._simspeed
            
            self._chan.send(cmd) # Assuming send handles serialization
        except ChannelClosed:
            logger.error("Cannot dispatch command: Channel is closed.")
            self.shutdown() # Mark as not running
        except Exception as e:
            logger.exception(f"Error dispatching command: {e}")
            # Decide if channel should be closed based on error type

    def _enqueue_buy(self, wh: int, prods: List[wam.AProduct]):
        cmd = wam.ACommands()
        r = cmd.buy.add()
        r.whnum = wh
        r.things.extend(prods)
        r.seqnum = self._next_seq()
        logger.info(f"Enqueuing BUY command (Seq={r.seqnum}): WH={wh}, {len(prods)} items")
        self._dispatch(cmd)

    def _enqueue_pack(self, wh: int, prods: List[wam.AProduct], ship: int):
        """Send PACK immediately if inventory already arrived, otherwise buffer."""
        if wh in self._inventory_ready:
            self._send_pack_now(wh, prods, ship)
        else:
            self._pending_pack.append((wh, prods, ship))
            logger.info("Buffered PACK for ship %d – waiting for inventory at warehouse %d.", ship, wh)

    def _send_pack_now(self, wh: int, prods: List[wam.AProduct], ship: int):
        """Actually send the PACK command to World."""
        cmd = wam.ACommands()
        # 在创建命令时就设置simspeed，而不是在最后
        cmd.simspeed = self._simspeed
        
        r = cmd.topack.add()
        r.whnum, r.shipid = wh, ship
        
        # 确保所有产品的description字段不为空
        validated_prods = []
        for prod in prods:
            if not prod.description:
                # 如果description为空，设置一个默认值
                logger.warning(f"Product id={prod.id} has empty description, setting default value")
                prod.description = f"product_{prod.id}"
            validated_prods.append(prod)
            
        r.things.extend(validated_prods)
        r.seqnum = self._next_seq()
        
        # 添加更详细的日志，包括完整的产品信息和simspeed
        logger.info(f"Enqueuing PACK command (Seq={r.seqnum}): WH={wh}, ShipID={ship}, {len(validated_prods)} items, simspeed={cmd.simspeed}")
        for p in validated_prods:
            logger.debug(f"  - Product: id={p.id}, desc='{p.description}', count={p.count}")
            
        # 打印原始protobuf的详细内容
        logger.debug(f"Raw PACK protobuf: {cmd}")
        
        # 删除这行，因为已经在前面设置了simspeed
        # cmd.simspeed = self._simspeed
        self._dispatch(cmd)

    def _enqueue_load(self, wh: int, truck: int, ship: int):
        cmd = wam.ACommands()
        r = cmd.load.add()
        r.whnum, r.truckid, r.shipid = wh, truck, ship
        r.seqnum = self._next_seq()
        logger.info(f"Enqueuing LOAD command (Seq={r.seqnum}): WH={wh}, Truck={truck}, ShipID={ship}")
        self._dispatch(cmd)

    def _enqueue_query(self, package: int):
        cmd = wam.ACommands()
        r = cmd.queries.add()
        r.packageid = package
        r.seqnum = self._next_seq()
        logger.info(f"Enqueuing QUERY command (Seq={r.seqnum}): PackageID={package}")
        self._dispatch(cmd)

    def _recv_loop(self):
        logger.info("Starting WorldClient receive loop...")
        while self._running:
            try:
                # Use a shorter timeout to periodically check self._running
                raw = self._chan.recv(timeout=1.0)
                if raw is None:
                    continue # Timeout, loop again

                resp = wam.AResponses()
                resp.ParseFromString(raw)

                # ACK bookkeeping
                if resp.acks:
                    for a in resp.acks:
                        self._chan.mark_acked(a)
                    # logger.debug(f"Marked ACKs: {list(resp.acks)}")

                processed_data = self._process_responses(resp)
                
                # 收到任何响应后立即发送ACK，不等下一个心跳周期
                # 这可以加速交互流程，减少延迟
                if self._acks_to_send:
                    try:
                        # 创建只包含ACK的空命令
                        ack_cmd = wam.ACommands(simspeed=self._simspeed)
                        ack_cmd.acks.extend(self._acks_to_send)
                        self._chan.send(ack_cmd)
                        logger.debug(f"Immediately sent ACKs: {self._acks_to_send}")
                        self._acks_to_send.clear()
                    except Exception as e:
                        logger.warning(f"Failed to send immediate ACKs: {e}")
                        # 失败时不清空_acks_to_send，让下一个心跳尝试发送
                
                if processed_data:
                    for item in processed_data:
                         logger.debug(f"Putting item on response queue: {item}")
                         self._response_queue.put(item)

                # Minimal logging
                if resp.error:
                    for e in resp.error:
                        logger.warning("World error: %s (seq=%d)", e.err, e.originseqnum)
                        # Also put errors on the queue
                        self._response_queue.put({
                            "type": "error",
                            "originseqnum": e.originseqnum,
                            "error_message": e.err,
                            "seqnum": e.seqnum # The error message seqnum itself
                        })

                if resp.finished:
                    logger.info("World requested shutdown -> disconnecting")
                    self._response_queue.put({"type": "finished"})
                    self.shutdown()
                    break

            except ChannelClosed:
                logger.info("Receive loop: Channel closed.")
                if self._running:
                     self._response_queue.put({"type": "disconnected"})
                self.shutdown()
                break
            except queue.Full:
                 logger.warning("Response queue is full. Responses may be lost.")
            except OSError as exc:
                if self._running:
                    logger.warning("OSError in receive loop: %s", exc)
                    if exc.errno == 9:  # Bad file descriptor
                        logger.info("Bad file descriptor error - channel likely closed")
                        self._response_queue.put({"type": "disconnected"})
                        self.shutdown()
                    else:
                        logger.exception("Receive loop encountered OSError: %s", exc)
                        self._response_queue.put({"type": "recv_loop_error", "error": str(exc)})
                break
            except Exception as exc:
                logger.exception("Receive loop crashed: %s", exc)
                self._response_queue.put({"type": "recv_loop_error", "error": str(exc)})
                self.shutdown()
                break
        logger.info("Receive loop stopped.")

    def _process_responses(self, resp: wam.AResponses) -> List[dict]:
        items = []
        for item in resp.arrived:
            # 记录每个仓库最近收到的商品信息
            whnum = item.whnum
            if whnum not in self._last_arrived:
                self._last_arrived[whnum] = []
                
            # 清空之前的记录，只保留最新一次ARRIVED
            self._last_arrived[whnum] = []
            
            # 存储商品信息
            for p in item.things:
                self._last_arrived[whnum].append({
                    'id': p.id,
                    'description': p.description,
                    'count': p.count
                })
                
            items.append({
                "type": "arrived",
                "whnum": item.whnum,
                "things": [{"id": p.id, "description": p.description, "count": p.count} for p in item.things],
                "seqnum": item.seqnum
            })
            # 收到 World 的 seqnum → 之后要回 ACK
            self._acks_to_send.append(item.seqnum)
            logger.info("World says items ARRIVED at warehouse %d (seq=%d)", item.whnum, item.seqnum)
            
            # 标记该仓库已收到库存
            self._inventory_ready.add(item.whnum)
            # 处理该仓库的所有等待中的PACK请求
            for wh, prods, ship in list(self._pending_pack):
                if wh == item.whnum:
                    logger.info(f"Inventory now available at WH={wh}, sending buffered PACK for shipment {ship}")
                    self._send_pack_now(wh, prods, ship)
                    self._pending_pack.remove((wh, prods, ship))
            
        for item in resp.ready:
             items.append({"type": "ready", "shipid": item.shipid, "seqnum": item.seqnum})
             # 收到 World 的 seqnum → 之后要回 ACK
             self._acks_to_send.append(item.seqnum)
             logger.info("World says shipment %d is PACKED (seq=%d)", item.shipid, item.seqnum)
             
        for item in resp.loaded:
             items.append({"type": "loaded", "shipid": item.shipid, "seqnum": item.seqnum})
             # 收到 World 的 seqnum → 之后要回 ACK
             self._acks_to_send.append(item.seqnum)
             logger.info("World says shipment %d is LOADED (seq=%d)", item.shipid, item.seqnum)
             
        for item in resp.packagestatus:
             items.append({"type": "packagestatus", "packageid": item.packageid, "status": item.status, "seqnum": item.seqnum})
             # 收到 World 的 seqnum → 之后要回 ACK
             self._acks_to_send.append(item.seqnum)
             logger.info("World says package %d status: %s (seq=%d)", item.packageid, item.status, item.seqnum)

        return items

    def _heartbeat_loop(self):
        """Periodically send an empty ACommands to keep the World alive."""
        while self._running:
            time.sleep(self.HEARTBEAT_SEC)
            try:
                beat = wam.ACommands(simspeed=self._simspeed)  # 带上simspeed，确保World不会忽略此帧
                # 携带待回 ACK
                if self._acks_to_send:
                    beat.acks.extend(self._acks_to_send)
                    self._acks_to_send.clear()
                self._chan.send(beat)
                logger.debug("Heartbeat sent (acks=%s)", getattr(beat, 'acks', []))
            except ChannelClosed:
                logger.info("Heartbeat channel closed")
                break
            except Exception as exc:
                logger.warning("Heartbeat error: %s", exc)
                break

    def shutdown(self):
        if not self._running:
            return
        logger.info("Shutting down WorldClient connection...")
        self._running = False
        try:
            if not self._chan.closed:
                 cmd = wam.ACommands(disconnect=True)
                 self._chan.send(cmd)
                 logger.info("Sent disconnect command.")
            else:
                 logger.info("Channel already closed, skipping disconnect command.")
        except Exception as e:
             logger.warning(f"Error sending disconnect command during shutdown: {e}")
        finally:
            self._chan.close()
            # 等待心跳线程结束
            if self._hb_thread and self._hb_thread.is_alive():
                self._hb_thread.join(timeout=1)
            logger.info("WorldClient connection closed.")

    def get_reliable_channel(self):
        """Returns the ReliableChannel instance for the InventoryService."""
        return self._chan
./tests/
./tests/db/

--- File: ./tests/db/__init__.py ---
# DB tests package 
./tests/db/__pycache__/

--- File: ./tests/db/test_models.py ---
import pytest
from amazon_app.models.base import Base
from amazon_app.models.product import Product
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

@pytest.mark.skip(reason="Local database connection issue, would run in CI environment")
def test_create_product():
    # 使用专用的测试引擎连接到Docker容器
    test_engine = create_engine("postgresql+psycopg2://amazon:amazon@localhost:5432/amazon")
    TestSessionLocal = sessionmaker(bind=test_engine)
    
    # 由于表已经存在，所以不需要create_all
    # Base.metadata.create_all(test_engine)
    
    with TestSessionLocal() as db:
        # 先清理可能存在的测试数据
        db.query(Product).filter_by(id=1).delete()
        db.commit()
        
        # 创建新数据并测试
        p = Product(id=1, description="book")
        db.add(p)
        db.commit()
        
        assert db.get(Product, 1).description == "book"
        
        # 清理测试数据
        db.query(Product).filter_by(id=1).delete()
        db.commit() 
./__pycache__/

--- File: ./setup.py ---
from setuptools import setup, find_packages

setup(
    name="amazon_app",
    version="0.1",
    packages=find_packages(),
) 
--- File: ./smoke_test.sh ---
#!/bin/bash
set -e

echo "== 1. BUY TEST =="
curl -X POST http://127.0.0.1:5001/buy \
     -H 'Content-Type: application/json' \
     -d '{
           "warehouse_id": 1,
           "products": [
             { "id": 101, "description": "book", "count": 5 }
           ]
         }'
echo -e "\n"

sleep 3  # 等待World回应

echo "== 2. PACK TEST =="
curl -X POST http://127.0.0.1:5001/pack \
     -H 'Content-Type: application/json' \
     -d '{
           "warehouse_id": 1,
           "shipment_id": 9001,
           "products": [
             { "id": 101, "description": "book", "count": 5 }
           ]
         }'
echo -e "\n"

echo "Waiting for shipment to be ready..."

tries=0
max_tries=60          # 把10提升到60（≈60秒）
sleep_step=1

while [ $tries -lt $max_tries ]; do
  ready=$(curl -s http://127.0.0.1:5001/status/summary | \
          jq -r '.shipment_readiness["9001"] // false')
  if [ "$ready" = "true" ]; then
    echo "Shipment is ready!"
    break
  fi
  tries=$((tries+1))
  echo "Waiting... $tries"
  sleep $sleep_step
  # 可选：越等越久，指数退避
  [ $((tries%10)) -eq 0 ] && sleep_step=$((sleep_step*2))
done

if [ "$ready" != "true" ]; then
  echo "Error: Waiting for shipment ready timeout"
  exit 1
fi

echo "== 3. LOAD TEST =="
curl -X POST http://127.0.0.1:5001/load \
     -H 'Content-Type: application/json' \
     -d '{
           "warehouse_id": 1,
           "truck_id": 3,
           "shipment_id": 9001
         }'
echo -e "\n"

sleep 3  # 等待World回应

echo "== 4. QUERY TEST =="
curl -X POST http://127.0.0.1:5001/query \
     -H 'Content-Type: application/json' \
     -d '{ "package_id": 9001 }'
echo -e "\n"

sleep 3  # 等待World回应

echo "== 5. STATUS CHECK =="
curl http://127.0.0.1:5001/package/9001/status
echo -e "\n"

echo "== 6. SUMMARY =="
curl http://127.0.0.1:5001/status/summary
echo -e "\n"

echo "Smoke test completed!" 
./world_simulator_exec-master/
./world_simulator_exec-master/docker_deploy/

--- File: ./world_simulator_exec-master/docker_deploy/wait-for-it.sh ---
#!/usr/bin/env bash
#   Use this script to test if a given TCP host/port are available

WAITFORIT_cmdname=${0##*/}

echoerr() { if [[ $WAITFORIT_QUIET -ne 1 ]]; then echo "$@" 1>&2; fi }

usage()
{
    cat << USAGE >&2
Usage:
    $WAITFORIT_cmdname host:port [-s] [-t timeout] [-- command args]
    -h HOST | --host=HOST       Host or IP under test
    -p PORT | --port=PORT       TCP port under test
                                Alternatively, you specify the host and port as host:port
    -s | --strict               Only execute subcommand if the test succeeds
    -q | --quiet                Don't output any status messages
    -t TIMEOUT | --timeout=TIMEOUT
                                Timeout in seconds, zero for no timeout
    -- COMMAND ARGS             Execute command with args after the test finishes
USAGE
    exit 1
}

wait_for()
{
    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then
        echoerr "$WAITFORIT_cmdname: waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT"
    else
        echoerr "$WAITFORIT_cmdname: waiting for $WAITFORIT_HOST:$WAITFORIT_PORT without a timeout"
    fi
    WAITFORIT_start_ts=$(date +%s)
    while :
    do
        if [[ $WAITFORIT_ISBUSY -eq 1 ]]; then
            nc -z $WAITFORIT_HOST $WAITFORIT_PORT
            WAITFORIT_result=$?
        else
            (echo > /dev/tcp/$WAITFORIT_HOST/$WAITFORIT_PORT) >/dev/null 2>&1
            WAITFORIT_result=$?
        fi
        if [[ $WAITFORIT_result -eq 0 ]]; then
            WAITFORIT_end_ts=$(date +%s)
            echoerr "$WAITFORIT_cmdname: $WAITFORIT_HOST:$WAITFORIT_PORT is available after $((WAITFORIT_end_ts - WAITFORIT_start_ts)) seconds"
            break
        fi
        sleep 1
    done
    return $WAITFORIT_result
}

wait_for_wrapper()
{
    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692
    if [[ $WAITFORIT_QUIET -eq 1 ]]; then
        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --quiet --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &
    else
        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &
    fi
    WAITFORIT_PID=$!
    trap "kill -INT -$WAITFORIT_PID" INT
    wait $WAITFORIT_PID
    WAITFORIT_RESULT=$?
    if [[ $WAITFORIT_RESULT -ne 0 ]]; then
        echoerr "$WAITFORIT_cmdname: timeout occurred after waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT"
    fi
    return $WAITFORIT_RESULT
}

# process arguments
while [[ $# -gt 0 ]]
do
    case "$1" in
        *:* )
        WAITFORIT_hostport=(${1//:/ })
        WAITFORIT_HOST=${WAITFORIT_hostport[0]}
        WAITFORIT_PORT=${WAITFORIT_hostport[1]}
        shift 1
        ;;
        --child)
        WAITFORIT_CHILD=1
        shift 1
        ;;
        -q | --quiet)
        WAITFORIT_QUIET=1
        shift 1
        ;;
        -s | --strict)
        WAITFORIT_STRICT=1
        shift 1
        ;;
        -h)
        WAITFORIT_HOST="$2"
        if [[ $WAITFORIT_HOST == "" ]]; then break; fi
        shift 2
        ;;
        --host=*)
        WAITFORIT_HOST="${1#*=}"
        shift 1
        ;;
        -p)
        WAITFORIT_PORT="$2"
        if [[ $WAITFORIT_PORT == "" ]]; then break; fi
        shift 2
        ;;
        --port=*)
        WAITFORIT_PORT="${1#*=}"
        shift 1
        ;;
        -t)
        WAITFORIT_TIMEOUT="$2"
        if [[ $WAITFORIT_TIMEOUT == "" ]]; then break; fi
        shift 2
        ;;
        --timeout=*)
        WAITFORIT_TIMEOUT="${1#*=}"
        shift 1
        ;;
        --)
        shift
        WAITFORIT_CLI=("$@")
        break
        ;;
        --help)
        usage
        ;;
        *)
        echoerr "Unknown argument: $1"
        usage
        ;;
    esac
done

if [[ "$WAITFORIT_HOST" == "" || "$WAITFORIT_PORT" == "" ]]; then
    echoerr "Error: you need to provide a host and port to test."
    usage
fi

WAITFORIT_TIMEOUT=${WAITFORIT_TIMEOUT:-15}
WAITFORIT_STRICT=${WAITFORIT_STRICT:-0}
WAITFORIT_CHILD=${WAITFORIT_CHILD:-0}
WAITFORIT_QUIET=${WAITFORIT_QUIET:-0}

# check to see if timeout is from busybox?
WAITFORIT_TIMEOUT_PATH=$(type -p timeout)
WAITFORIT_TIMEOUT_PATH=$(realpath $WAITFORIT_TIMEOUT_PATH 2>/dev/null || readlink -f $WAITFORIT_TIMEOUT_PATH)
if [[ $WAITFORIT_TIMEOUT_PATH =~ "busybox" ]]; then
        WAITFORIT_ISBUSY=1
        WAITFORIT_BUSYTIMEFLAG="-t"

else
        WAITFORIT_ISBUSY=0
        WAITFORIT_BUSYTIMEFLAG=""
fi

if [[ $WAITFORIT_CHILD -gt 0 ]]; then
    wait_for
    WAITFORIT_RESULT=$?
    exit $WAITFORIT_RESULT
else
    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then
        wait_for_wrapper
        WAITFORIT_RESULT=$?
    else
        wait_for
        WAITFORIT_RESULT=$?
    fi
fi

if [[ $WAITFORIT_CLI != "" ]]; then
    if [[ $WAITFORIT_RESULT -ne 0 && $WAITFORIT_STRICT -eq 1 ]]; then
        echoerr "$WAITFORIT_cmdname: strict mode, refusing to execute subprocess"
        exit $WAITFORIT_RESULT
    fi
    exec "${WAITFORIT_CLI[@]}"
else
    exit $WAITFORIT_RESULT
fi
./static/
./scripts/

--- File: ./scripts/compile_protos.sh ---
#!/bin/bash

# Script to compile protobuf files to Python

# Set directories
PROTO_DIR="../amazon_app/protocols"
PYTHON_OUT_DIR="../amazon_app/protocols"

# Create the output directory if it doesn't exist
mkdir -p "$PYTHON_OUT_DIR"

# Find all .proto files and compile them
echo "Compiling protobuf files..."
for proto_file in $(find "$PROTO_DIR" -name "*.proto"); do
  echo "Compiling $proto_file..."
  python -m grpc_tools.protoc \
    -I"$PROTO_DIR" \
    --python_out="$PYTHON_OUT_DIR" \
    --grpc_python_out="$PYTHON_OUT_DIR" \
    "$proto_file"
done

echo "Compilation complete!"

--- File: ./app.py ---
# app.py

import os
import sys
import logging
import threading
import queue
import time
from flask import Flask, request, jsonify

# --- Configuration and Imports ---
try:
    import config
    from amazon_app.services.world_client import WorldClient
    from amazon_app.services.inventory_service import InventoryService
    from amazon_app.db import SessionLocal
    # Adjust import based on your actual protobuf file location/name
    # Example: from amazon_app.protocols import world_amazon_1_pb2 as wam
    import amazon_app.pb_generated.world_amazon_1_pb2 as wam
except ImportError as e:
    print(f"Error importing modules: {e}. Ensure config.py, world_client.py, "
          "and the protobuf definitions exist and are importable.")
    sys.exit(1)

# --- Basic Logging Setup ---
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Flask App Initialization ---
app = Flask(__name__)
app.config.from_object(config)

# --- Shared State and Queue ---
# Queue for responses from WorldClient's _recv_loop
response_queue = queue.Queue(maxsize=100) # Set a maxsize

# Simple in-memory state (Replace with DB for persistence)
# WARNING: Direct dict access is NOT thread-safe if using multiple Flask workers.
# Use thread-safe structures or DB for production.
package_statuses = {}
shipment_readiness = {} # shipid -> bool
shipment_loaded_status = {} # shipid -> bool
warehouse_inventory = {} # whnum -> {product_id: count} - Simplified
world_errors = []
state_lock = threading.Lock() # To protect access to shared dictionaries

# --- WorldClient Instance ---
# Create after app is defined, before running
logger.info("Initializing WorldClient...")
world_client = WorldClient(
    host=app.config['WORLD_HOST'],
    port=app.config['WORLD_PORT'],
    response_queue=response_queue
)

# --- Initialize InventoryService ---
logger.info("Initializing InventoryService...")
inventory_service = InventoryService(SessionLocal, world_client.get_reliable_channel())

# --- Response Processing Worker ---
def response_processor_worker():
    """Runs in a background thread, processing messages from WorldClient."""
    logger.info("Starting response processor worker thread...")
    while True:
        try:
            # Blocks until an item is available in the queue
            item = response_queue.get()
            logger.info(f"Processing item from queue: {item.get('type', 'UNKNOWN')}")

            item_type = item.get("type")

            with state_lock: # Lock when modifying shared state
                if item_type == "arrived":
                    # Example: Update inventory (very basic)
                    wh = item.get("whnum")
                    if wh not in warehouse_inventory:
                        warehouse_inventory[wh] = {}
                    for prod in item.get("things", []):
                        prod_id = prod.get("id")
                        count = prod.get("count", 0)
                        warehouse_inventory[wh][prod_id] = warehouse_inventory[wh].get(prod_id, 0) + count
                    logger.info(f"Inventory updated for WH {wh}: {warehouse_inventory[wh]}")

                elif item_type == "ready":
                    ship_id = item.get("shipid")
                    if ship_id is not None:
                        shipment_readiness[ship_id] = True
                        logger.info(f"Shipment {ship_id} marked as ready.")

                elif item_type == "loaded":
                    ship_id = item.get("shipid")
                    if ship_id is not None:
                        shipment_loaded_status[ship_id] = True
                        # Maybe remove from readiness?
                        # shipment_readiness.pop(ship_id, None)
                        logger.info(f"Shipment {ship_id} marked as loaded.")

                elif item_type == "packagestatus":
                    pkg_id = item.get("packageid")
                    status = item.get("status")
                    if pkg_id is not None:
                        package_statuses[pkg_id] = status
                        logger.info(f"Status updated for package {pkg_id}: {status}")

                elif item_type == "error":
                    world_errors.append(item)
                    logger.warning(f"World error received: originseqnum={item.get('originseqnum')}, error_message='{item.get('error_message')}'")
                    # 提取具体的失败操作类型
                    failed_seq = item.get('originseqnum')
                    logger.warning(f"Command with seqnum={failed_seq} failed. Check previous logs to identify which operation this was.")

                elif item_type == "finished":
                    logger.warning("World simulator finished. Application might stop functioning correctly.")
                    # Potentially trigger app shutdown or alert
                    break # Stop processing if world says it's done

                elif item_type == "disconnected":
                     logger.error("World disconnected unexpectedly.")
                     # Potentially trigger app shutdown or alert
                     break # Stop processing

                elif item_type == "recv_loop_error":
                    logger.error(f"Receive loop error reported: {item.get('error')}")
                    break # Stop processing

                else:
                    logger.warning(f"Received unknown item type from queue: {item_type}")

            # Important: Signal that the task from the queue is done
            response_queue.task_done()

        except Exception as e:
            logger.exception(f"Error in response_processor_worker: {e}")
            # Avoid dying; maybe sleep and retry or log and continue?
            time.sleep(1)

    logger.info("Response processor worker thread stopped.")


# --- API Endpoints ---

@app.route('/')
def index():
    """Basic health check."""
    return jsonify({"status": "ok", "world_client_running": world_client._running})

@app.route('/buy', methods=['POST'])
def handle_buy():
    """Endpoint to trigger a purchase."""
    if not world_client._running:
         return jsonify({"error": "World client not connected"}), 503

    data = request.get_json()
    if not data or 'warehouse_id' not in data or 'products' not in data:
        return jsonify({"error": "Missing warehouse_id or products"}), 400

    wh_id = data['warehouse_id']
    products_data = data['products'] # Expecting list of {'id': N, 'description': 'S', 'count': N}

    try:
        products = []
        for p_data in products_data:
            if not all(k in p_data for k in ('id', 'description', 'count')):
                return jsonify({"error": f"Invalid product data: {p_data}"}), 400
            prod = wam.AProduct(id=p_data['id'], description=p_data['description'], count=p_data['count'])
            products.append(prod)

        world_client.buy(wh=wh_id, prods=products)
        # Note: We don't get immediate confirmation here, just that the command was sent.
        # The confirmation ('arrived' message) comes via the queue later.
        return jsonify({"message": "Buy command sent to world"}), 202 # 202 Accepted
    except Exception as e:
        logger.exception(f"Error processing /buy request: {e}")
        return jsonify({"error": "Internal server error processing request"}), 500


@app.route('/pack', methods=['POST'])
def handle_pack():
    """Endpoint to trigger packing a shipment."""
    if not world_client._running:
         return jsonify({"error": "World client not connected"}), 503

    data = request.get_json()
    if not data or not all(k in data for k in ('warehouse_id', 'products', 'shipment_id')):
        return jsonify({"error": "Missing warehouse_id, products, or shipment_id"}), 400

    wh_id = data['warehouse_id']
    ship_id = data['shipment_id']
    products_data = data['products']

    try:
        products = []
        for p_data in products_data:
             if not all(k in p_data for k in ('id', 'description', 'count')):
                return jsonify({"error": f"Invalid product data: {p_data}"}), 400
             prod = wam.AProduct(id=p_data['id'], description=p_data['description'], count=p_data['count'])
             products.append(prod)

        world_client.pack(wh=wh_id, prods=products, shipid=ship_id)
        return jsonify({"message": "Pack command sent to world"}), 202
    except Exception as e:
        logger.exception(f"Error processing /pack request: {e}")
        return jsonify({"error": "Internal server error processing request"}), 500

@app.route('/load', methods=['POST'])
def handle_load():
    """Endpoint to trigger loading a shipment onto a truck."""
    if not world_client._running:
         return jsonify({"error": "World client not connected"}), 503

    data = request.get_json()
    if not data or not all(k in data for k in ('warehouse_id', 'truck_id', 'shipment_id')):
        return jsonify({"error": "Missing warehouse_id, truck_id, or shipment_id"}), 400

    wh_id = data['warehouse_id']
    truck_id = data['truck_id']
    ship_id = data['shipment_id']

    try:
        # 检查shipment是否ready
        with state_lock:
            if not shipment_readiness.get(ship_id):
                logger.warning(f"Attempted to load shipment {ship_id} which is not marked as ready.")
                return jsonify({"error": f"Shipment {ship_id} not ready for loading"}), 409

        world_client.load(wh=wh_id, truckid=truck_id, shipid=ship_id)
        return jsonify({"message": "Load command sent to world"}), 202
    except Exception as e:
        logger.exception(f"Error processing /load request: {e}")
        return jsonify({"error": "Internal server error processing request"}), 500

@app.route('/query', methods=['POST'])
def handle_query():
    """Endpoint to query package status."""
    if not world_client._running:
         return jsonify({"error": "World client not connected"}), 503

    data = request.get_json()
    if not data or 'package_id' not in data:
        return jsonify({"error": "Missing package_id"}), 400

    package_id = data['package_id']

    try:
        world_client.query(packageid=package_id)
        return jsonify({"message": "Query command sent to world"}), 202
    except Exception as e:
        logger.exception(f"Error processing /query request: {e}")
        return jsonify({"error": "Internal server error processing request"}), 500

@app.route('/package/<int:package_id>/status', methods=['GET'])
def get_package_status(package_id):
    """Endpoint to get the last known status of a package from our state."""
    with state_lock: # Lock for reading shared state
        status = package_statuses.get(package_id)

    if status is not None:
        return jsonify({"package_id": package_id, "status": status})
    else:
        # Check if a query was ever sent, maybe? For now, just 404
        return jsonify({"error": "Package status not found or not yet received"}), 404

@app.route('/status/summary', methods=['GET'])
def get_status_summary():
    """Provides a summary of the current known state."""
    with state_lock:
        summary = {
            "package_statuses": dict(package_statuses), # Create copies
            "shipment_readiness": dict(shipment_readiness),
            "shipment_loaded_status": dict(shipment_loaded_status),
            "warehouse_inventory_summary": {wh: list(inv.keys()) for wh, inv in warehouse_inventory.items()}, # Just keys for brevity
            "world_errors": list(world_errors),
            "world_client_running": world_client._running,
            "response_queue_size": response_queue.qsize(),
        }
    return jsonify(summary)


# --- Application Startup ---
if __name__ == '__main__':
    logger.info("Starting Flask application...")

    # 启用详细日志，便于观察通信过程
    logging.getLogger('amazon_app.utils.reliable_channel').setLevel(logging.DEBUG)
    logging.getLogger('amazon_app.services.world_client').setLevel(logging.DEBUG)

    # Prepare initial warehouse data for WorldClient connect
    initial_warehouses = []
    for wh_data in app.config.get('INITIAL_WAREHOUSES_DATA', []):
        try:
            wh = wam.AInitWarehouse(id=wh_data['id'], x=wh_data['x'], y=wh_data['y'])
            initial_warehouses.append(wh)
        except KeyError as e:
            logger.error(f"Invalid warehouse data in config: Missing key {e} in {wh_data}")
            sys.exit(1)

    # Connect to the World Simulator
    logger.info(f"Connecting to World Simulator at {app.config['WORLD_HOST']}:{app.config['WORLD_PORT']}...")
    try:
        world_id = world_client.connect(warehouses=initial_warehouses)
        if world_id is None:
             logger.error("Failed to connect to World Simulator. Exiting.")
             sys.exit(1) # Exit if connection failed
        logger.info(f"Successfully connected to World Simulator with worldid: {world_id}")
    except Exception as e:
        logger.exception(f"Unhandled exception during WorldClient connection: {e}")
        sys.exit(1)


    # Start the background thread for processing responses
    response_thread = threading.Thread(target=response_processor_worker, daemon=True)
    response_thread.start()
    logger.info("Response processor thread started.")

    # Start the Flask development server
    # IMPORTANT: use_reloader=False is often necessary when managing background threads
    # or singleton objects like WorldClient, as the reloader can cause multiple
    # initializations or issues with thread management.
    logger.info("Starting Flask development server...")
    app.run(host='0.0.0.0', port=5001, debug=True, use_reloader=False)

    # --- Cleanup (won't usually run in debug mode, but good practice) ---
    logger.info("Flask app stopping...")
    world_client.shutdown() # Gracefully disconnect from world sim
    # Optionally wait for the response thread?
    # response_queue.join() # Wait for queue to be empty (might block indefinitely if worker died)
    logger.info("Application shutdown complete.")
./templates/
./venv/

--- File: ./print_all.sh ---
#!/usr/bin/env bash
set -euo pipefail

output_file="output.txt"

> "$output_file"

echo "=== PROJECT FILE STRUCTURE ===" >> "$output_file"
find . -type f -not -path "*/\.*" -not -path "*/venv/*" | sort | sed -e 's/[^-][^\/]*\//  |/g' -e 's/|\([^ ]\)/|-\1/' >> "$output_file"
echo -e "\n" >> "$output_file"

while IFS= read -r -d '' path; do
  if [ -d "$path" ]; then
    echo "${path}/" >> "$output_file"
  else
    if [[ "$path" == *.py || "$path" == *.proto || "$path" == *.sh ]]; then
      echo -e "\n--- File: $path ---" >> "$output_file"
      cat "$path" >> "$output_file"
    fi
  fi
done < <(find . -not -path "*/\.*" -not -path "*/venv/*" -print0)

echo "Saved to $output_file"
